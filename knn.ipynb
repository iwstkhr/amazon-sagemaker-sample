{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%env S3_DATASET_BUCKET={{YOUR_S3_BUCKET}}\n",
    "%env S3_DATASET_TRAIN=knn/input/iris_train.csv\n",
    "%env S3_DATASET_TEST=knn/input/iris_test.csv\n",
    "%env S3_TRAIN_OUTPUT=knn/output\n",
    "%env SAGEMAKER_ROLE={{YOUR_SAGEMAKER_ROLE}}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import string\n",
    "\n",
    "import boto3\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sagemaker\n",
    "from IPython.display import display\n",
    "from sagemaker import image_uris\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "from sagemaker.estimator import Estimator, Predictor\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Define constants\n",
    "CSV_PATH = './tmp/iris.csv'\n",
    "S3_DATASET_BUCKET = os.getenv('S3_DATASET_BUCKET')\n",
    "S3_DATASET_TRAIN = os.getenv('S3_DATASET_TRAIN')\n",
    "S3_DATASET_TEST = os.getenv('S3_DATASET_TEST')\n",
    "S3_TRAIN_OUTPUT = os.getenv('S3_TRAIN_OUTPUT')\n",
    "SAGEMAKER_ROLE = os.getenv('SAGEMAKER_ROLE')\n",
    "ESTIMATOR_INSTANCE_COUNT = 1\n",
    "ESTIMATOR_INSTANCE_TYPE = 'ml.m5.large'\n",
    "PREDICTOR_INSTANCE_TYPE = 'ml.t2.medium'\n",
    "PREDICTOR_ENDPOINT_NAME = f'sagemaker-knn-{PREDICTOR_INSTANCE_TYPE}'.replace('.', '-')\n",
    "\n",
    "# Define variables used over this notebook\n",
    "bucket = boto3.resource('s3').Bucket(S3_DATASET_BUCKET)\n",
    "train_df = None\n",
    "test_df = None\n",
    "train_object_path = None\n",
    "test_object_path = None\n",
    "knn = None\n",
    "predictor = None"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Download a sample csv\n",
    "!mkdir -p tmp\n",
    "!curl -o \"$(pwd)/tmp/iris.csv\" -L https://raw.githubusercontent.com/aws/amazon-sagemaker-examples/master/hyperparameter_tuning/r_bring_your_own/iris.csv"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "############################################################\n",
    "# Data preparation\n",
    "############################################################\n",
    "\n",
    "def load_csv(path: str) -> pd.DataFrame:\n",
    "    \"\"\" Load a csv file to transform pandas DataFrame\n",
    "\n",
    "    Args:\n",
    "        path (str): Path to a csv file\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame to be trained\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(path)\n",
    "    # Move the last label column to the first\n",
    "    # See https://docs.aws.amazon.com/sagemaker/latest/dg/cdf-training.html#cdf-csv-format\n",
    "    df = df[['Species', 'Sepal.Length', 'Sepal.Width', 'Petal.Length', 'Petal.Width']]\n",
    "    # Convert target string to int\n",
    "    df['Species'] = df['Species'].map({'setosa': 0, 'versicolor': 1, 'virginica': 2})\n",
    "    return df\n",
    "\n",
    "\n",
    "def plot(df: pd.DataFrame) -> None:\n",
    "    \"\"\" Plot DataFrame\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame which you want to plot\n",
    "    \"\"\"\n",
    "    pd.plotting.scatter_matrix(df, figsize=(15, 15), c=df['Species'])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def upload_csv_to_s3(df: pd.DataFrame, object_path: str) -> str:\n",
    "    \"\"\" Upload a csv file to be trained by SageMaker\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame which is saved as csv format\n",
    "        object_path (str): An S3 object path under your specified bucket\n",
    "\n",
    "    Returns:\n",
    "        str: An S3 object uri\n",
    "    \"\"\"\n",
    "    filename = ''.join([random.choice(string.digits + string.ascii_lowercase) for i in range(10)])\n",
    "    path = os.path.abspath(os.path.join('./tmp', filename))\n",
    "    df.to_csv(path, header=False, index=False)\n",
    "    # Change content-type because the default is binary/octet-stream\n",
    "    bucket.upload_file(path, object_path, ExtraArgs={'ContentType': 'text/csv'})\n",
    "    return f's3://{bucket.name}/{object_path}'\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Prepare data\n",
    "    df = load_csv(CSV_PATH)\n",
    "    display(df)\n",
    "    plot(df)\n",
    "    train_df, test_df = train_test_split(df, shuffle=True, random_state=0)  # type: (pd.DataFrame, pd.DataFrame)\n",
    "\n",
    "    train_object_path = upload_csv_to_s3(train_df, S3_DATASET_TRAIN)\n",
    "    test_object_path = upload_csv_to_s3(test_df, S3_DATASET_TEST)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "############################################################\n",
    "# Model build\n",
    "############################################################\n",
    "\n",
    "def get_estimator(**hyperparams) -> Estimator:\n",
    "    \"\"\" Get a SageMaker estimator\n",
    "\n",
    "    Args:\n",
    "        **hyperparams: Hyperparameters\n",
    "\n",
    "    Returns:\n",
    "        Estimator: A SageMaker estimator to which necessary arguments and hyperparameters are set\n",
    "    \"\"\"\n",
    "    estimator = Estimator(\n",
    "        image_uri=image_uris.retrieve('knn', boto3.Session().region_name),  # AWS provided container in ECR,\n",
    "        role=SAGEMAKER_ROLE,\n",
    "        instance_count=ESTIMATOR_INSTANCE_COUNT,\n",
    "        instance_type=ESTIMATOR_INSTANCE_TYPE,\n",
    "        input_mode='Pipe',\n",
    "        output_path=f's3://{S3_DATASET_BUCKET}/{S3_TRAIN_OUTPUT}',\n",
    "        sagemaker_session=sagemaker.Session(),\n",
    "    )\n",
    "    hyperparams.update({'predictor_type': 'classifier'})\n",
    "    estimator.set_hyperparameters(**hyperparams)\n",
    "    return estimator\n",
    "\n",
    "\n",
    "def train(estimator: Estimator, train_object_path: str, test_object_path: str) -> None:\n",
    "    \"\"\" Train a SageMaker estimator synchronously\n",
    "\n",
    "    Args:\n",
    "        estimator (Estimator): A SageMaker estimator to be trained\n",
    "        train_object_path (str): An S3 object path used as train data\n",
    "        test_object_path (str): An S3 object path used as test data\n",
    "    \"\"\"\n",
    "    # Specify content-type because the default is application/x-recordio-protobuf\n",
    "    train_input = TrainingInput(train_object_path, content_type='text/csv', input_mode='Pipe')\n",
    "    test_input = TrainingInput(test_object_path, content_type='text/csv', input_mode='Pipe')\n",
    "    estimator.fit({'train': train_input, 'test': test_input})\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    knn = get_estimator(k=1, sample_size=1000)\n",
    "    train(knn, train_object_path, test_object_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "############################################################\n",
    "# Model deploy\n",
    "############################################################\n",
    "\n",
    "def deploy(estimator: Estimator) -> Predictor:\n",
    "    \"\"\" Deploy a SageMaker estimator and create an inference endpoint\n",
    "\n",
    "    Args:\n",
    "        estimator (Estimator): A SageMaker estimator to be deployed\n",
    "\n",
    "    Returns:\n",
    "        Predictor: A SageMaker predictor which you use for inference\n",
    "    \"\"\"\n",
    "    return estimator.deploy(\n",
    "        initial_instance_count=1,\n",
    "        instance_type=PREDICTOR_INSTANCE_TYPE,\n",
    "        serializer=CSVSerializer(),\n",
    "        deserializer=JSONDeserializer(),\n",
    "        endpoint_name=PREDICTOR_ENDPOINT_NAME\n",
    "    )\n",
    "\n",
    "\n",
    "def validate(predictor: Predictor, test_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\" Get pandas DataFrame for validation\n",
    "\n",
    "    This does not include scores such as accuracy, precision, etc.\n",
    "\n",
    "    Args:\n",
    "        predictor (Predictor): A SageMaker predictor\n",
    "        test_df (pd.DataFrame): Test data\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: pandas DataFrame to be used for validation\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "\n",
    "    for i, data in test_df.iterrows():\n",
    "        predict = predictor.predict(\n",
    "            pd.DataFrame([data.drop('Species')]).to_csv(header=False, index=False),\n",
    "            initial_args={'ContentType': 'text/csv'}\n",
    "        )\n",
    "        predicted_label = predict['predictions'][0]['predicted_label']\n",
    "\n",
    "        row = data.tolist()\n",
    "        row.append(predicted_label)\n",
    "        row.append(data['Species'] == predicted_label)\n",
    "        rows.extend([row])\n",
    "\n",
    "    return pd.DataFrame(rows, columns=('Species', 'Sepal.Length', 'Sepal.Width', 'Petal.Length', 'Petal.Width', 'Prediction', 'Result'))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    predictor = deploy(knn)\n",
    "    predictions = validate(predictor, test_df)\n",
    "    display(predictions)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "############################################################\n",
    "# Delete a model and an inference endpoint\n",
    "############################################################\n",
    "\n",
    "def delete_model(predictor: Predictor) -> None:\n",
    "    \"\"\" Delete a SageMaker model\n",
    "\n",
    "    Args:\n",
    "        predictor (Predictor): A SageMaker predictor\n",
    "    \"\"\"\n",
    "    try:\n",
    "        predictor.delete_model()\n",
    "        print(f'Deleted a model')\n",
    "    except BaseException as e:\n",
    "        print(e)\n",
    "\n",
    "\n",
    "def delete_endpoint(predictor: Predictor) -> None:\n",
    "    \"\"\" Delete a SageMaker endpoint including a SageMaker endpoint config\n",
    "\n",
    "    Args:\n",
    "        predictor (Predictor): A SageMaker predictor\n",
    "    \"\"\"\n",
    "    try:\n",
    "        predictor.delete_endpoint(delete_endpoint_config=True)\n",
    "        print(f'Deleted {predictor.endpoint_name}')\n",
    "    except BaseException as e:\n",
    "        print(e)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    delete_model(predictor)\n",
    "    delete_endpoint(predictor)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}